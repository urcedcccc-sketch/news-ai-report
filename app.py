import streamlit as st
import requests
from openai import OpenAI
from datetime import datetime, timedelta

# 1. å¯†é’¥åˆå§‹åŒ–
try:
    OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
    TIAN_API_KEY = st.secrets["TIAN_API_KEY"]
except Exception as e:
    st.error("å¯†é’¥é…ç½®é”™è¯¯ï¼Œè¯·æ£€æŸ¥ Streamlit Secretsã€‚")
    st.stop()

client = OpenAI(api_key=OPENAI_API_KEY)

# é¡µé¢è®¾ç½®
st.set_page_config(page_title="å…¨åŸŸæ™ºèƒ½å†…å‚ç³»ç»Ÿ", layout="wide")
st.title("ğŸ—ï¸ å…¨åŸŸæ™ºèƒ½å†…å‚ç³»ç»Ÿ")
st.caption("å¤šæºå¹¶å‘æ£€ç´¢ | è‡ªåŠ¨èšåˆæç‚¼ | ä¸¥æ ¼ 7 å¤©æ—¶æ•ˆ")

# 2. ä¾§è¾¹æ é…ç½® (UI æç®€ä¼˜åŒ–)
with st.sidebar:
    st.header("æ£€ç´¢è®¾ç½®")
    word = st.text_input("è¯·è¾“å…¥æ ¸å¿ƒå…³é”®è¯", "ä¼Šæœ—")
    num_limit = st.slider("æœ€å¤§å±•ç¤ºæ€»ç¯‡æ•°", 1, 30, 10)
    
    st.divider()
    st.info("ğŸ“Œ ç³»ç»Ÿå·²å¼€å¯â€˜å…¨æºè”åŠ¨â€™ï¼šç‚¹å‡»åŒæ­¥åï¼Œåå°å°†è‡ªåŠ¨æ£€ç´¢å›½é™…ã€å›½å†…ã€äº’è”ç½‘åŠç»¼åˆæ–°é—»ã€‚")
    btn = st.button("å¼€å§‹åŒæ­¥å…¨åŸŸå†…å‚", type="primary")

# 3. æ ¸å¿ƒå·¥å…·å‡½æ•°
def is_within_a_week(date_str):
    """æ—¶æ•ˆæ‹¦æˆªï¼šç¡®ä¿åªæœ‰7å¤©å†…çš„æ–°é—»èƒ½é€šè¿‡"""
    if not date_str: return False
    try:
        fmt = "%Y-%m-%d %H:%M:%S" if ":" in date_str else "%Y-%m-%d"
        news_date = datetime.strptime(date_str[:19], fmt)
        return datetime.now() - news_date <= timedelta(days=7)
    except:
        return True

def fetch_all_sources(kw):
    """æ ¸å¿ƒï¼šåå°å¹¶å‘æ£€ç´¢å››å¤§æ¥å£"""
    endpoints = {
        "å›½é™…æ–°é—»": "https://apis.tianapi.com/world/index",
        "å›½å†…æ–°é—»": "https://apis.tianapi.com/guonei/index",
        "äº’è”ç½‘èµ„è®¯": "https://apis.tianapi.com/internet/index",
        "ç»¼åˆæ–°é—»": "https://apis.tianapi.com/generalnews/index"
    }
    
    aggregated_news = []
    
    # é€ä¸€è¯·æ±‚æ¥å£å¹¶æ‰“ä¸Šæ¥æºæ ‡ç­¾
    for name, url in endpoints.items():
        params = {"key": TIAN_API_KEY, "num": 30, "word": kw.strip()}
        try:
            res = requests.get(url, params=params, timeout=8).json()
            if res.get("code") == 200:
                news_list = res.get("result", {}).get("newslist", [])
                for n in news_list:
                    n["source_tag"] = name # æ ‡è®°æ•°æ®æ¥è‡ªå“ªä¸ªæ¥å£
                aggregated_news.extend(news_list)
        except:
            continue
            
    # æŒ‰æ—¶é—´å€’åºæ’åˆ— (æœ€æ–°çš„åœ¨å‰)
    aggregated_news.sort(key=lambda x: x.get('ctime', ''), reverse=True)
    return aggregated_news

# 4. ä¸»æ¸²æŸ“é€»è¾‘
if btn:
    if not word:
        st.warning("âš ï¸ è¯·è¾“å…¥å…³é”®è¯åå†æ‰§è¡ŒåŒæ­¥ã€‚")
        st.stop()

    status = st.empty()
    status.info(f"æ­£åœ¨è·¨æºåŒæ­¥å…³äºã€{word}ã€çš„å…¨åŸŸæ•°æ®å¹¶è¿›è¡Œ AI æç‚¼...")
    
    # èšåˆæ•°æ®è·å–
    all_data = fetch_all_sources(word)
    
    # æ—¶æ•ˆæ€§è¿‡æ»¤ + ç¯‡æ•°æˆªå–
    final_list = [n for n in all_data if is_within_a_week(n.get('ctime'))][:num_limit]

    if not final_list:
        st.error(f"ğŸ” å…¨åŸŸæ£€ç´¢å®Œæ¯•ï¼Œæœªå‘ç°æœ€è¿‘ 7 å¤©å†…å…³äºã€{word}ã€çš„æœ‰æ•ˆæŠ¥é“ã€‚")
    else:
        status.success(f"âœ… å…¨åŸŸåŒæ­¥æˆåŠŸï¼šå·²ä»å››å¤§æºä¸­æç‚¼å‡º {len(final_list)} æ¡æœ¬å‘¨é«˜ä»·å€¼å†…å‚")
        
        for news in final_list:
    with st.container(border=True):
        title = news.get('title', 'æ— æ ‡é¢˜')
        source = news.get('source', 'æƒå¨åª’ä½“')
        tag = news.get('source_tag', 'æœªçŸ¥åˆ†ç±»')
        ctime = news.get('ctime', 'åˆšåˆš')
        
        # ä¼˜åŒ–ç‚¹ 1ï¼šè·å–çœŸå®ç´ æï¼Œå¦‚æœä¸ºç©ºåˆ™ä½¿ç”¨æ ‡é¢˜å…œåº•
        desc = news.get('description') or news.get('digest')
        raw_desc = desc if desc and len(desc) > 10 else "æš‚æ— è¯¦ç»†æ­£æ–‡"
        
        col1, col2 = st.columns([1, 4])
        with col1:
            st.write(f"**{source}**")
            st.caption(f"ğŸ“… {ctime}")
            st.caption(f"ğŸ“‚ åˆ†ç±»ï¼š{tag}")
        with col2:
            # ä¼˜åŒ–ç‚¹ 2ï¼šåªæœ‰å½“ç´ æå­—æ•°è¶³å¤Ÿæ—¶æ‰è°ƒç”¨ AI
            if desc and len(desc) > 20:
                try:
                    # æ”¹è¿›çš„æç¤ºè¯ï¼šå¼ºè°ƒä¸¥è°¨æ€§ï¼Œå‡å°‘è¯¯å¯¼
                    prompt = (
                        f"ä½ æ˜¯ä¸€åç§°èŒçš„æ–°é—»ç¼–è¾‘ã€‚è¯·é’ˆå¯¹ä»¥ä¸‹ç´ æè¿›è¡Œæç‚¼ï¼š\n"
                        f"ã€æ ‡é¢˜ã€‘ï¼š{title}\n"
                        f"ã€æ­£æ–‡ã€‘ï¼š{desc}\n"
                        f"è¦æ±‚ï¼šä¸¥æ ¼åŸºäºæ­£æ–‡ï¼Œå†™ä¸€æ®µ100å­—ä»¥å†…çš„æ·±åº¦æ€»ç»“ï¼Œè¦æ±‚åŒ…å«äº‹ä»¶æ ¸å¿ƒå’Œæ½œåœ¨å½±å“ã€‚è‹¥æ­£æ–‡å†…å®¹ä¸è¶³ï¼Œè¯·ç›´æ¥æ¦‚æ‹¬æ ‡é¢˜ã€‚"
                    )
                    
                    completion = client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=[{"role": "user", "content": prompt}],
                        temperature=0.2 # è°ƒä½éšæœºæ€§ï¼Œå‡å°‘å¹»è§‰
                    )
                    st.markdown(f"### {title}")
                    st.info(completion.choices[0].message.content)
                except:
                    st.markdown(f"### {title}")
                    st.write(raw_desc)
            else:
                # ç´ æå¤ªå°‘ï¼Œç›´æ¥æ˜¾ç¤ºæ ‡é¢˜å’ŒåŸæ–‡æ‘˜è¦ï¼Œä¸æµªè´¹ Token ä¸”æ›´å‡†ç¡®
                st.markdown(f"### {title}")
                st.write(f"âš ï¸ åŸå§‹ç´ æè¿‡çŸ­ï¼Œè¯·ç‚¹å‡»ä¸‹æ–¹é“¾æ¥æŸ¥çœ‹åŸæ–‡è¯¦æƒ…ã€‚")
                st.caption(f"å†…å®¹ç®€è¿°ï¼š{raw_desc}")
            
            if news.get('url'):
                st.markdown(f"ğŸ”— [é˜…è¯»åŸå‘æŠ¥é“]({news['url']})")
    
    status.empty()
